{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9389</td>\n",
       "      <td>While arguing over President Reagan’s 1981 tax...</td>\n",
       "      <td>Sarah Sanders</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>1</td>\n",
       "      <td>[34218, 55700, 18736, 39031, 34219, 34220]</td>\n",
       "      <td>10354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1861</td>\n",
       "      <td>Recently Rick Scott \"closed 30 women’s health ...</td>\n",
       "      <td>Lois Frankel</td>\n",
       "      <td>2014-09-12</td>\n",
       "      <td>0</td>\n",
       "      <td>[73190, 76997, 38841, 77415, 77303, 9280, 8332...</td>\n",
       "      <td>2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11035</td>\n",
       "      <td>Says Target installed urinals in a women’s bat...</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>0</td>\n",
       "      <td>[9619, 22197]</td>\n",
       "      <td>12160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12221</td>\n",
       "      <td>Says \"combined doses of vaccines\" have never b...</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>0</td>\n",
       "      <td>[57163, 31528, 40908, 31536, 68904, 44601]</td>\n",
       "      <td>13458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11354</td>\n",
       "      <td>:   The AMBER Alert system has been discontinu...</td>\n",
       "      <td></td>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>0</td>\n",
       "      <td>[103978, 121475, 121849]</td>\n",
       "      <td>12504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2910</td>\n",
       "      <td>Health insurance costs for Floridians are up 3...</td>\n",
       "      <td>Republican Party of Florida</td>\n",
       "      <td>2014-09-23</td>\n",
       "      <td>1</td>\n",
       "      <td>[9581, 89571, 7836, 7945, 7949, 77360, 83491, ...</td>\n",
       "      <td>3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6096</td>\n",
       "      <td>A photograph captures Harriet Tubman as a \"Gun...</td>\n",
       "      <td></td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>0</td>\n",
       "      <td>[125108, 125968, 126005]</td>\n",
       "      <td>6701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10446</td>\n",
       "      <td>ISIS leader Abu Bakr al Baghdadi was \"released...</td>\n",
       "      <td>Jeanine  Pirro</td>\n",
       "      <td>2014-06-14</td>\n",
       "      <td>0</td>\n",
       "      <td>[80115, 93998, 5968, 175, 91475, 8710, 89881, ...</td>\n",
       "      <td>11514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5414</td>\n",
       "      <td>\"The board of a nonprofit organization on whic...</td>\n",
       "      <td>Tennessee Republican Party</td>\n",
       "      <td>2008-02-25</td>\n",
       "      <td>1</td>\n",
       "      <td>[96453, 71123, 61, 69968, 96477]</td>\n",
       "      <td>5966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6657</td>\n",
       "      <td>Japan announced plans to dump 920,000 tons of ...</td>\n",
       "      <td></td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>1</td>\n",
       "      <td>[120293, 132262]</td>\n",
       "      <td>7328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12444 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   claim  \\\n",
       "9389   While arguing over President Reagan’s 1981 tax...   \n",
       "1861   Recently Rick Scott \"closed 30 women’s health ...   \n",
       "11035  Says Target installed urinals in a women’s bat...   \n",
       "12221  Says \"combined doses of vaccines\" have never b...   \n",
       "11354  :   The AMBER Alert system has been discontinu...   \n",
       "...                                                  ...   \n",
       "2910   Health insurance costs for Floridians are up 3...   \n",
       "6096   A photograph captures Harriet Tubman as a \"Gun...   \n",
       "10446  ISIS leader Abu Bakr al Baghdadi was \"released...   \n",
       "5414   \"The board of a nonprofit organization on whic...   \n",
       "6657   Japan announced plans to dump 920,000 tons of ...   \n",
       "\n",
       "                          claimant        date  label  \\\n",
       "9389                 Sarah Sanders  2017-10-31      1   \n",
       "1861                  Lois Frankel  2014-09-12      0   \n",
       "11035               Facebook posts  2016-04-22      0   \n",
       "12221               Facebook posts  2019-04-15      0   \n",
       "11354                               2013-10-13      0   \n",
       "...                            ...         ...    ...   \n",
       "2910   Republican Party of Florida  2014-09-23      1   \n",
       "6096                                2019-03-25      0   \n",
       "10446               Jeanine  Pirro  2014-06-14      0   \n",
       "5414    Tennessee Republican Party  2008-02-25      1   \n",
       "6657                                2017-08-22      1   \n",
       "\n",
       "                                        related_articles     id  \n",
       "9389          [34218, 55700, 18736, 39031, 34219, 34220]  10354  \n",
       "1861   [73190, 76997, 38841, 77415, 77303, 9280, 8332...   2053  \n",
       "11035                                      [9619, 22197]  12160  \n",
       "12221         [57163, 31528, 40908, 31536, 68904, 44601]  13458  \n",
       "11354                           [103978, 121475, 121849]  12504  \n",
       "...                                                  ...    ...  \n",
       "2910   [9581, 89571, 7836, 7945, 7949, 77360, 83491, ...   3208  \n",
       "6096                            [125108, 125968, 126005]   6701  \n",
       "10446  [80115, 93998, 5968, 175, 91475, 8710, 89881, ...  11514  \n",
       "5414                    [96453, 71123, 61, 69968, 96477]   5966  \n",
       "6657                                    [120293, 132262]   7328  \n",
       "\n",
       "[12444 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('../input/train_set.pkl')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_claims = list(zip(train.claim, train.label))\n",
    "# train_claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('../input/test_set.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model based on multinomial naive-bayes\n",
    "nb_claims = make_pipeline(TfidfVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('multinomialnb',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with training data\n",
    "nb_claims.fit(train['claim'], train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create labels for test data\n",
    "y_pred = nb_claims.predict(test['claim'])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6023786563805851"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check accuracy of model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = test['label']\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to file\n",
    "with open('../input/nb_claims.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_claims, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # and later you can load it\n",
    "# with open('filename.pkl', 'rb') as f:\n",
    "#     clf = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
