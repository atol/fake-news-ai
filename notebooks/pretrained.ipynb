{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "METADATA_FILEPATH = '../dataset/metadata.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources: \n",
    "\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "\n",
    "https://towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(METADATA_FILEPATH, 'r') as f:\n",
    "    metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>claimant</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>related_articles</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A line from George Orwell's novel 1984 predict...</td>\n",
       "      <td></td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>[122094, 122580, 130685, 134765]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Maine legislature candidate Leslie Gibson insu...</td>\n",
       "      <td></td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>2</td>\n",
       "      <td>[106868, 127320, 128060]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A 17-year-old girl named Alyssa Carson is bein...</td>\n",
       "      <td></td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>[132130, 132132, 149722]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>In 1988 author Roald Dahl penned an open lette...</td>\n",
       "      <td></td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>[123254, 123418, 127464]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>When it comes to fighting terrorism, \"Another ...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>[41099, 89899, 72543, 82644, 95344, 88361]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Rhode Island is \"almost dead last\" among North...</td>\n",
       "      <td>Leonidas Raptakis</td>\n",
       "      <td>2014-02-11</td>\n",
       "      <td>2</td>\n",
       "      <td>[8284, 3768, 20091, 82368, 73148, 4493]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>The poorest counties in the U.S. are in Appala...</td>\n",
       "      <td>Jim Webb</td>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>1</td>\n",
       "      <td>[70709, 70708]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Koch Industries paid the legal fees of George ...</td>\n",
       "      <td></td>\n",
       "      <td>2013-07-18</td>\n",
       "      <td>0</td>\n",
       "      <td>[120591, 120592, 127866, 129483]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>\"Minnesota, Michigan, Iowa already have 70 mph...</td>\n",
       "      <td>Robin Vos</td>\n",
       "      <td>2013-08-22</td>\n",
       "      <td>1</td>\n",
       "      <td>[69547, 80095, 7994, 81116, 77621]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>\"FBI Uniform Crime Report for 2016 shows more ...</td>\n",
       "      <td>Nick Schroer</td>\n",
       "      <td>2017-10-17</td>\n",
       "      <td>1</td>\n",
       "      <td>[72012, 26005, 43481, 55671]</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim           claimant  \\\n",
       "0  A line from George Orwell's novel 1984 predict...                      \n",
       "1  Maine legislature candidate Leslie Gibson insu...                      \n",
       "2  A 17-year-old girl named Alyssa Carson is bein...                      \n",
       "3  In 1988 author Roald Dahl penned an open lette...                      \n",
       "4  When it comes to fighting terrorism, \"Another ...    Hillary Clinton   \n",
       "5  Rhode Island is \"almost dead last\" among North...  Leonidas Raptakis   \n",
       "6  The poorest counties in the U.S. are in Appala...           Jim Webb   \n",
       "7  Koch Industries paid the legal fees of George ...                      \n",
       "8  \"Minnesota, Michigan, Iowa already have 70 mph...          Robin Vos   \n",
       "9  \"FBI Uniform Crime Report for 2016 shows more ...       Nick Schroer   \n",
       "\n",
       "         date  label                            related_articles  id  \n",
       "0  2017-07-17      0            [122094, 122580, 130685, 134765]   0  \n",
       "1  2018-03-17      2                    [106868, 127320, 128060]   1  \n",
       "2  2018-07-18      1                    [132130, 132132, 149722]   4  \n",
       "3  2019-02-04      2                    [123254, 123418, 127464]   5  \n",
       "4  2016-03-22      2  [41099, 89899, 72543, 82644, 95344, 88361]   6  \n",
       "5  2014-02-11      2     [8284, 3768, 20091, 82368, 73148, 4493]   7  \n",
       "6  2014-11-19      1                              [70709, 70708]   8  \n",
       "7  2013-07-18      0            [120591, 120592, 127866, 129483]   9  \n",
       "8  2013-08-22      1          [69547, 80095, 7994, 81116, 77621]  11  \n",
       "9  2017-10-17      1                [72012, 26005, 43481, 55671]  12  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15555"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_SEQUENCE_LENGTH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = list()\n",
    "lines = df['claim'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    tokens = word_tokenize(line)\n",
    "    # convert to lowercase\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    claims.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15555"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(claims)\n",
    "sequences = tokenizer.texts_to_sequences(claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21392 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label'].values\n",
    "labels = to_categorical(np.asarray(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (15555, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data tensor:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (15555, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of label tensor:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "X_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train tensor: (12444, 1000)\n",
      "Shape of y_train tensor: (12444, 3)\n",
      "Shape of X_val tensor: (3111, 1000)\n",
      "Shape of y_val tensor: (3111, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train tensor:\", X_train.shape)\n",
    "print(\"Shape of y_train tensor:\", y_train.shape)\n",
    "\n",
    "print(\"Shape of X_val tensor:\", X_val.shape)\n",
    "print(\"Shape of y_val tensor:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(\"../reference/glove.6B.300d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a 1D convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Flatten, LSTM, GRU\n",
    "from keras.layers import Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = Dropout(0.4)(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12444 samples, validate on 3111 samples\n",
      "Epoch 1/10\n",
      "12444/12444 [==============================] - 120s 10ms/step - loss: 0.9570 - accuracy: 0.5144 - val_loss: 0.9725 - val_accuracy: 0.5731\n",
      "Epoch 2/10\n",
      "12444/12444 [==============================] - 121s 10ms/step - loss: 0.9166 - accuracy: 0.5715 - val_loss: 0.9388 - val_accuracy: 0.5805\n",
      "Epoch 3/10\n",
      "12444/12444 [==============================] - 122s 10ms/step - loss: 0.8993 - accuracy: 0.5869 - val_loss: 0.9213 - val_accuracy: 0.5876\n",
      "Epoch 4/10\n",
      "12444/12444 [==============================] - 121s 10ms/step - loss: 0.8843 - accuracy: 0.6022 - val_loss: 0.9196 - val_accuracy: 0.5802\n",
      "Epoch 5/10\n",
      "12444/12444 [==============================] - 136s 11ms/step - loss: 0.8683 - accuracy: 0.6070 - val_loss: 0.9195 - val_accuracy: 0.5927\n",
      "Epoch 6/10\n",
      "12444/12444 [==============================] - 120s 10ms/step - loss: 0.8556 - accuracy: 0.6193 - val_loss: 0.9203 - val_accuracy: 0.5873\n",
      "Epoch 7/10\n",
      "12444/12444 [==============================] - 122s 10ms/step - loss: 0.8437 - accuracy: 0.6236 - val_loss: 0.9031 - val_accuracy: 0.5934\n",
      "Epoch 8/10\n",
      "12444/12444 [==============================] - 120s 10ms/step - loss: 0.8246 - accuracy: 0.6375 - val_loss: 0.9037 - val_accuracy: 0.5943\n",
      "Epoch 9/10\n",
      "12444/12444 [==============================] - 121s 10ms/step - loss: 0.8028 - accuracy: 0.6540 - val_loss: 0.9028 - val_accuracy: 0.6017\n",
      "Epoch 10/10\n",
      "12444/12444 [==============================] - 122s 10ms/step - loss: 0.7879 - accuracy: 0.6616 - val_loss: 0.9054 - val_accuracy: 0.5895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4632f5b668>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "          epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
